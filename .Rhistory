# t:      time
# psi:    fraction of indolent cancers
# lambda: exponential rate of progression to clinical
#         state for progressive cancers
####################################################
Q.surv <- function(t, psi, lambda)
return(psi+(1-psi)*exp(-lambda*t))
####################################################
# Screen-detected cancers: Likelihood contribution
#
# theta: model parameters
# t:     vector of times
# j:     screen number [0, 1, 2, 3, ...]
####################################################
D.j <- function(theta, t, j){
psi <- theta[1]
lambda <- theta[2]
w <- theta[3]
beta <- theta[4]
out <- 0
j <- j+2
for(k in 2:j){
out <- out+beta*(1-beta)^(j-k)*(psi*(exp(-w*t[k-1])-exp(-w*t[k]))+w*(1-psi)/(lambda-w)*(exp(t[k]*(lambda-w)-lambda*t[j])-exp(t[k-1]*(lambda-w)-lambda*t[j])))
}
# correction 6/14
out <- out*exp(w*t[1])
return(out)
}
####################################################
# Interval-detected cancers: Likelihood contribution
# prior to last screen
#
# theta: model parameters
# t:     vector of times
# j:     screen number [0, 1, 2, 3, ...]
####################################################
I.j <- function(theta, t, j){
psi <- theta[1]
lambda <- theta[2]
w <- theta[3]
beta <- theta[4]
j <- j+2
out <- 0
for(k in 2:j){
a <- exp(-lambda*t[j]+t[k]*(lambda-w))-exp(-lambda*t[j+1]+t[k]*(lambda-w))
b <- exp(-lambda*t[j]+t[k-1]*(lambda-w))-exp(-lambda*t[j+1]+t[k-1]*(lambda-w))
out <- out+(1-beta)^(j-k+1)*(a-b)
}
out <- (1-psi)*w/(lambda-w)*out
out <- out+(1-psi)*(exp(-w*t[j])-exp(-w*t[j+1])-w/(lambda-w)*(exp(-t[j+1]*w)-exp(-lambda*t[j+1]+(lambda-w)*t[j])))
# correction 6/14
out <- out*exp(w*t[1])
return(out)
}
####################################################
# Interval-detected cancers: Likelihood contribution
# after last screen
#
# theta: model parameters
# t:     vector of times
# l:     year of follow up [1, ..., L]
####################################################
Ifin.l <- function(theta, t, l){
psi <- theta[1]
lambda <- theta[2]
w <- theta[3]
beta <- theta[4]
J <- length(t)-1 # index of last screen
tJ <- t[J] # time of last screen
L <- t[J+1]-t[J] # number of follow-up years after last screen
out <- 0
out <- exp(-lambda-w*(tJ+l-1))-exp(-l*lambda-w*tJ)
for(k in 2:J){
out <- out+(1-beta)^(J-k+1)*(exp(-w*t[k]-lambda*(tJ+l-t[k]))-exp(-w*t[k-1]-lambda*(tJ+l-t[k-1])))
}
out <- out*w/(lambda-w)*(exp(lambda)-1)
out <- out+exp(-w*(tJ+l-1))-exp(-w*(tJ+l))
out <- out-w/(lambda-w)*(exp(-w*(tJ+l))-exp(-lambda-w*(tJ+l-1)))
out <- (1-psi)*out
# correction 6/14
out <- out*exp(w*t[1])
return(out)
}
####################################################
# Conditioning on T_P+T_C>t_0
#
# theta: model parameters
# t0:    time of first screen
####################################################
CF.fun <- function(theta, t0){
psi <- theta[1]
lambda <- theta[2]
w <- theta[3]
out <- psi+(1-psi)*(exp(-w*t0)+w/(lambda-w)*(exp(-t0*w)-exp(-t0*lambda)))
return(out)
}
##################################################
# Full Likelihood with 4 parameters
# Use full likelihood to estimate 4 parameters
# psi:    proportion of non-progressive cancers
# lambda: exponential rate of progression to clinical
#         state for progressive cancers
# w:      incidence of preclinical disease (N->P/I)
# beta:   screening sensitivity
#
# Hardcoded parameter inputs:
#   Time of onset of susceptibility to P/I
#   Screening times
##################################################
EstPsiBMucstab4Full.fun <- function(x, y, t, z, clin.FU) {
# x: vector of parameters (psi, lambda, w, beta)
# y: rows are: y[1:3, ]=matrix(s[1], r[1], n[1],
#                              s[2], r[2], n[2],
#                              ..., ..., ...)
#    where s is the number of screen detections and
#          r is the number of interval cases
#          n is the number of participants
# z: if z[1] > 0: it is the number of parameters to be fixed
#       z[2]: value of the parameter
if (sum(z[[1]]) > 0){
theta <- rep(-1, 4)
theta[z[[1]]] <- z[[2]]
theta[theta == -1] <- x
} else {
theta <- x
}
n.y <- nrow(y)
##################################################
# Calculate probability of screen detection at
# each exam
##################################################
v <- t(0:(n.y-1))
d <- apply(v, 2, function(x) D.j(theta, t, x))
##################################################
# Calculate probability of clinical diagnosis in
# each interval
##################################################
q <- apply(v, 2, function(x) I.j(theta, t, x))
##################################################
# Calculate and return full log likelihood
##################################################
# old version with only one normalization term (approximation)
#n.f <- rep(CF.fun(theta, t[2]-t[1]), n.y)
#n.f <- rep(1, n.y)
# NEW version with exact normalization terms
n.f <- rep(CF.fun(theta, t[2]-t[1]), n.y)
QQ <- cumsum(d+q)
n.f[2:n.y] <- n.f[2:n.y]-QQ[1:(n.y-1)]
fin <- 0
# step 1: all but the last round
for(jj in 1:(n.y-1)){
fin <- fin-(y[jj, 1]*log(d[jj]/n.f[jj])+y[jj, 2]*log(q[jj]/n.f[jj])+(y[jj, 3]-y[jj, 1]-y[jj, 2])*log(1-d[jj]/n.f[jj]-q[jj]/n.f[jj]))
}
# step 2: the last round
# The screen-detection contribution
fin <- fin-y[n.y, 1]*log(d[n.y]/n.f[n.y])
# The annual clinical incidence contributions
p <- apply(t(1:length(clin.FU)), 2, function(x) Ifin.l(theta, t, x))
fin <- fin-clin.FU %*% log(p/n.f[n.y])
fin <- fin-(y[n.y, 3]-y[n.y, 1]-sum(clin.FU))*log(1-d[n.y]/n.f[n.y]-sum(p)/n.f[n.y])
return(fin)
}
##################################################
# Calculate profile likelihoods
##################################################
flikelihood <- function(x0,
xl,
xu,
t.vec,
trial.data,
last.screen,
z=c(0, 0),
likelihood=EstPsiBMucstab4Full.fun){
opt <- nlminb(start=x0,
obj=likelihood,
lower=xl,
upper=xu,
y=trial.data,
t=t.vec,
z=z,
clin.FU=last.screen)
return(with(opt, list(objective=objective, params=par)))
}
plikelihood <- function(x0,
xl,
xu,
t.vec,
trial.data,
last.screen,
p.grid,
fopt=NA,
z=c(0, 0),
likelihood=EstPsiBMucstab4Full.fun,
problem=0,
noindolent=FALSE){
nvalues <- nrow(p.grid)
if(all(is.na(fopt)))
fopt <- flikelihood(x0,
xl,
xu,
t.vec,
trial.data,
last.screen,
z=c(0, 0),
likelihood=likelihood)
LL <- data.frame(psi=numeric(nvalues),
lambda=numeric(nvalues),
w=numeric(nvalues),
beta=numeric(nvalues))
freenames <- allnames <- names(p.grid)
if(noindolent){
LL <- LL[-psi]
freenames <- setdiff(freenames, 'psi')
}
for(fixed in freenames){
for(j in 1:nvalues){
if(noindolent)
z <- list(c(1, match(fixed, allnames)), c(0, p.grid[j, fixed]))
else
z <- c(match(fixed, allnames), p.grid[j, fixed])
popt <- nlminb(start=x0[setdiff(freenames, fixed)],
obj=likelihood,
lower=xl[setdiff(freenames, fixed)],
upper=xu[setdiff(freenames, fixed)],
y=trial.data,
t=t.vec,
z=z,
clin.FU=last.screen)
problem <- problem+popt$convergence
if(problem)
warning('Convegence problem for ', fixed, '=', p.grid[j, fixed])
LL[j, fixed] <- popt$objective-fopt$objective
}
}
return(LL)
}
##################################################
# Control default plotting theme aesthetics
##################################################
gg_theme <- function(...){
theme_set(theme_bw())
theme_update(panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
panel.spacing=unit(0.03, 'npc'),
axis.text=element_text(colour='black', size=10),
axis.title=element_text(size=12),
axis.title.y=element_text(size=12, angle=90, vjust=0.5),
axis.line=element_line(colour='black'),
aspect.ratio=1,
strip.background=element_rect(fill=NA, colour=NA),
strip.text.x=element_text(angle=0, size=14))
theme_update(...)
}
##################################################
# Illustrate profile likelihoods
##################################################
pframe <- function(p.grid, p.like, parname, simulation=NA)
data.frame(param=p.grid[, parname],
NLL=pmax(p.like[, parname], 0),
simulation=simulation)
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
library(grid)
# Make a list from the ... arguments and plotlist
plots <- c(list(...), plotlist)
numPlots = length(plots)
# If layout is NULL, then use 'cols' to determine layout
if (is.null(layout)) {
# Make the panel
# ncol: Number of columns of plots
# nrow: Number of rows needed, calculated from # of cols
layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
ncol = cols, nrow = ceiling(numPlots/cols))
}
if (numPlots==1) {
print(plots[[1]])
} else {
# Set up the page
grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
# Make each plot, in the correct location
for (i in 1:numPlots) {
# Get the i,j matrix positions of the regions that contain this subplot
matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
layout.pos.col = matchidx$col))
}
}
}
##################################################
# Simulation study parameters
# psi:    fraction of indolent cancers
# lambda: mean sojourn time for progressive cancers
# w:      hazard rate for onset of P/I
# beta:   screening sensitivity
##################################################
x.vec <- c(psi=0.2, lambda=1/2.5, w=0.0025, beta=0.8)
##################################################
# Initial values and limits for optimization algorithm
##################################################
x0 <- c(psi=0.5, lambda=1, w=1/100, beta=0.5)
xl <- c(psi=0, lambda=0, w=0, beta=0)
xu <- c(psi=1, lambda=5, w=5, beta=1)
##################################################
# t.vec:  vector of ages where w becomes >0, screens, and last follow-up
##################################################
t.vec <- c(20, 50:54, 60)
##################################################
# Generate the data
##################################################
set.seed(444)
source('synthetic_data_2017-06-26.r')
##################################################
# Calculate profile likelihood over parameter grid
##################################################
p.grid <- pgrid(x.vec)
p.like <- plikelihood(x0, xl, xu, t.vec, trial.data, last.screen, p.grid)
##################################################
# Illustrate profile likelihoods
##################################################
ppanel <- function(x.vec, p.grid, p.like, parname, xmax=NA){
dset <- pframe(p.grid, p.like, parname)
gg_theme()
gg <- ggplot(data=dset)
gg <- gg+geom_line(aes(x=param, y=NLL), size=1)
gg <- gg+geom_hline(yintercept=CI.line,
linetype='dotted',
colour='gray30',
size=0.75)
gg <- gg+geom_vline(xintercept=x.vec[parname],
linetype='dashed',
colour='gray30',
size=0.75)
if(is.na(xmax)){
xmax <- ifelse(parname == 'w', 0.01, 1)
xstep <- ifelse(parname == 'w', 0.002, 0.2)
} else {
xstep <- xmax/5
}
gg <- gg+scale_x_continuous(name=parse(text=parname),
breaks=seq(0, xmax, by=xstep),
expand=c(0, 0))
gg <- gg+scale_y_continuous(name='Negative log-likelihood',
breaks=seq(0, 10, by=2),
expand=c(0, 0))
gg <- gg+coord_cartesian(xlim=c(0, xmax), ylim=c(-1, 10))
return(gg)
}
grid.arrange(ppanel(x.vec, p.grid, p.like, 'psi'),
ppanel(x.vec, p.grid, p.like, 'lambda'),
ppanel(x.vec, p.grid, p.like, 'w'),
ppanel(x.vec, p.grid, p.like, 'beta'),
layout_matrix=matrix(c(1, 2, 3, 4),
ncol=2,
byrow=TRUE))
##################################################
# Show example target and estimated parameters
##################################################
load(file.path(loadpath, 'Bias_SE_Estimator', 'Bias_SE_stats_7_19_2017.RData'))
format_table1 <- function(dset){
names(dset) <- sapply(names(dset),
switch,
'psi'='$\\psi$',
'lambda'='$\\lambda$',
'w'='$w$',
'beta'='$\\beta$',
'psi.se'='SE($\\hat{\\psi}$)',
'lambda.se'='SE($\\hat{\\lambda}$)',
'w.se'='SE($\\hat{w}$)',
'beta.se'='SE($\\hat{\\beta}$)',
'T2E'='T2E')
rownames(dset) <- c('Target', 'Estimate')
print(xtable(dset, digits=4, align=c('l', rep('c', 9))),
hline.after=0,
comment=FALSE,
sanitize.colnames.function=function(x) {x})
}
format_table1(fff)
##################################################
# Illustrate heatmaps of runs achieving API and
# runs rejecting H0: psi=0 with follow-up to
# specified ages
##################################################
apiplot <- function(dset, par1, par2, responses){
melted <- melt(dset, id.vars=c(par1, par2, 'followup'))
melted <- rename(melted, c(variable='response', value='proportion'))
melted <- subset(melted, response %in% responses)
melted <- transform(melted,
followup=paste('Follow-up~to~age', followup, sep='~'),
response=sapply(as.character(response),
switch,
'IdM'='Runs~achieving~API',
'LRM'='Runs~rejecting~psi==0'))
gg_theme(axis.title=element_text(size=18),
axis.title.y=element_text(size=18, angle=0, vjust=0.5),
aspect.ratio=1,
strip.text.y=element_text(angle=270, size=14))
gg <- ggplot(data=melted, aes_string(x=par1, y=par2))
gg <- gg+geom_raster(aes(fill=proportion), interpolate=FALSE)
gg <- gg+facet_grid(response~followup, labeller=label_parsed)
gg <- gg+scale_x_continuous(name=parse(text=par1),
labels=percent_format(),
expand=c(0, 0))
gg <- gg+scale_y_log10(name=parse(text=par2),
breaks=c(0.1, 0.5, 1.0, 2.0),
expand=c(0, 0))
gg <- gg+scale_fill_gradient(name='',
labels=percent_format(),
low='black',
high='white',
limits=c(0, 1),
expand=c(0, 0),
guide=guide_colorbar(draw.ulim=FALSE,
draw.llim=FALSE,
label.hjust=1))
print(gg)
}
##################################################
# Read and merge saved results of runs achieving
# API and runs rejecting H0: psi=0 after 1 or 6
# years of clinical follow-up after last screen.
##################################################
load(file.path(loadpath, 'Systematic_IA_60', 'Exp_60_identifiability.RData'))
result_mat_60 <- transform(result_mat, IdM=IdM/max(IdM), LRM=LRM/max(LRM))
load(file.path(loadpath, 'Systematic_IA_55', 'Exp_55_identifiability.RData'))
result_mat_55 <- transform(result_mat, IdM=IdM/max(IdM), LRM=LRM/max(LRM))
dset <- rbind(transform(result_mat_55, followup=55),
transform(result_mat_60, followup=60))
apiplot(dset, par1='psi', par2='lambda', responses=c('IdM', 'LRM'))
##################################################
# Read saved results of simulations achieving API
##################################################
load(file.path(loadpath, 'Systematic_FU', 'Systematic_FU_psi_p2.RData'))
psi.p4 <- data.frame(psi=0.4, api=result_mat$IdM)
load(file.path(loadpath, 'Systematic_FU', 'Systematic_FU_psi_p4.RData'))
psi.p6 <- data.frame(psi=0.6, api=result_mat$IdM)
load(file.path(loadpath, 'Systematic_FU', 'Systematic_FU_psi_p6.RData'))
psi.p8 <- data.frame(psi=0.8, api=result_mat$IdM)
psi.dat <- rbind(psi.p4, psi.p6, psi.p8)
##################################################
# Calculate follow-up since final screen using
# time vector excluding last entry
##################################################
screen.vec <- c(20, 50:54)
fu.years <- FU.bound-screen.vec[length(screen.vec)]
psi.dat <- cbind(psi.dat, fu.years)
##################################################
# Illustrate simulations achieving API
##################################################
apanel <- function(dset, titulo){
dset <- transform(dset, psi=factor(psi))
gg_theme(legend.position='none')
gg <- ggplot(data=dset)
gg <- gg+geom_line(aes(x=fu.years,
y=api/100,
group=psi,
colour=psi),
size=1)
gg <- gg+geom_point(aes(x=fu.years,
y=api/100,
group=psi,
colour=psi),
size=4)
gg <- gg+scale_x_continuous(name='Years of follow-up',
limits=c(0, 10),
breaks=seq(0, 14, by=2))
gg <- gg+scale_y_continuous(name='Runs achieving API',
limits=c(0, 1),
breaks=seq(0, 1, by=0.2),
labels=percent_format())
gg <- gg+scale_colour_grey() + ggtitle(titulo)
return(gg)
}
aaa <- psi.dat
#print(apanel(psi.dat))
##################################################
# Read saved results of simulations achieving API
##################################################
load(file.path(loadpath, 'Systematic_FU', 'Systematic_FU_MST_4_psi_p2.RData'))
psi.p4 <- data.frame(psi=0.4, api=result_mat$IdM)
load(file.path(loadpath, 'Systematic_FU', 'Systematic_FU_MST_4_psi_p4.RData'))
psi.p6 <- data.frame(psi=0.6, api=result_mat$IdM)
load(file.path(loadpath, 'Systematic_FU', 'Systematic_FU_MST_4_psi_p6.RData'))
psi.p8 <- data.frame(psi=0.8, api=result_mat$IdM)
psi.dat <- rbind(psi.p4, psi.p6, psi.p8)
##################################################
# Calculate follow-up since final screen using
# time vector excluding last entry
##################################################
screen.vec <- c(20, 50:54)
fu.years <- FU.bound-screen.vec[length(screen.vec)]
psi.dat <- cbind(psi.dat, fu.years)
##################################################
# Juxtapose simulations with mean sojourn times of
# 6 months or 4 years using multiplot
##################################################
bbb <- psi.dat
multiplot(apanel(aaa, "A: MST of 6 months"), apanel(bbb, "B: MST of 4 years"), cols=2)
install.packages('/Users/mdr30/Downloads/setwidth_1.0-4.tar', repos = NULL, type="source")
library(setwidth)
install.packages('/Users/mdr30/Downloads/setwidth_1.0-4.tar', repos = NULL)
install.packages('/Users/mdr30/Downloads/setwidth_1.0-4.tar')
install.packages('/Users/mdr30/Downloads/setwidth_1.0-4.tar', repos=NULL, type="source")
