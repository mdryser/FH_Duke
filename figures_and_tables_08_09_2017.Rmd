---
title: "Figures and Tables"
output:
  pdf_document: default
  html_document: default
---

```{r setup, echo=FALSE}
##################################################
# Load libraries
##################################################
library(knitr)
library(reshape)
library(xtable)
library(grid)
library(scales)
library(ggplot2)
library(gridExtra)

##################################################
# Control knitr options
##################################################
opts_chunk$set(echo=FALSE,
               message=FALSE,
               warning=FALSE,
               cache=TRUE,
               fig.width=6,
               fig.asp=1,
               out.width='100%')

##################################################
# Path to saved data
##################################################
#loadpath <- file.path('',
#                      'Users',
#                      'mdr30',
#                      'ownCloud',
#                      'DCIS',
#                      'Fred_Hutch',
#                      'Paper_Simulations',
#                      'Exponential_v4')
loadpath <- '.'

##################################################
# Save figures as requested by AJE technical review 
##################################################
aje_formatted <- TRUE

##################################################
# Confidence level for profile likelihood CIs
##################################################
alpha.level <- 0.05
CI.line <- qchisq(1-alpha.level, 1)/2

##################################################
# Simulation study trial size
##################################################
N <- 50000

##################################################
# The profile likelihood parameter grid
# scale.factor: scale rate window
# per.factor:   scale the probability window
##################################################
# pgrid <- function(x, nvalues=50, scale.factor=3, per.factor=0.2)
#     data.frame(psi=seq(from=max(0, x['psi']-per.factor),
#                        to=min(1, x['psi']+per.factor),
#                        length.out=nvalues),
#                lambda=10^seq(from=log10(x['lambda']/scale.factor),
#                              to=log10(x['lambda']*scale.factor),
#                              length.out=nvalues),
#                w=10^seq(from=log10(x['w']/scale.factor),
#                         to=log10(x['w']*scale.factor),
#                         length.out=nvalues),
#                beta=seq(from=max(0, x['beta']-per.factor),
#                         to=min(1, x['beta']+per.factor),
#                         length.out=nvalues))

# WATCH OUT
pgrid <- function(x, nvalues=100, scale.factor=6, per.factor=1)
  data.frame(psi=seq(from=max(0, x['psi']-per.factor),
                     to=min(1, x['psi']+per.factor),
                     length.out=nvalues),
             lambda=10^seq(from=log10(x['lambda']/scale.factor),
                           to=log10(x['lambda']*scale.factor),
                           length.out=nvalues),
             w=10^seq(from=log10(x['w']/scale.factor),
                      to=log10(x['w']*scale.factor),
                      length.out=nvalues),
             beta=seq(from=max(0, x['beta']-per.factor),
                      to=min(1, x['beta']+per.factor),
                      length.out=nvalues))

##################################################
# Source likelihood functions
##################################################
# source('likelihood_2017-06-26.r')

####################################################
# Survival function for U (mixture progression time)
#
# t:      time
# psi:    fraction of indolent cancers
# lambda: exponential rate of progression to clinical
#         state for progressive cancers
####################################################
Q.surv <- function(t, psi, lambda)
  return(psi+(1-psi)*exp(-lambda*t))

####################################################
# Screen-detected cancers: Likelihood contribution
#
# theta: model parameters
# t:     vector of times
# j:     screen number [0, 1, 2, 3, ...]
####################################################
D.j <- function(theta, t, j){
  psi <- theta[1]
  lambda <- theta[2]
  w <- theta[3]
  beta <- theta[4]
  out <- 0
  j <- j+2
  for(k in 2:j){
    out <- out+beta*(1-beta)^(j-k)*(psi*(exp(-w*t[k-1])-exp(-w*t[k]))+w*(1-psi)/(lambda-w)*(exp(t[k]*(lambda-w)-lambda*t[j])-exp(t[k-1]*(lambda-w)-lambda*t[j])))
  }
  # correction 6/14
  out <- out*exp(w*t[1])
  return(out)
}

####################################################
# Interval-detected cancers: Likelihood contribution
# prior to last screen
#
# theta: model parameters
# t:     vector of times
# j:     screen number [0, 1, 2, 3, ...]
####################################################
I.j <- function(theta, t, j){
  psi <- theta[1]
  lambda <- theta[2]
  w <- theta[3]
  beta <- theta[4]
  j <- j+2
  out <- 0
  for(k in 2:j){
    a <- exp(-lambda*t[j]+t[k]*(lambda-w))-exp(-lambda*t[j+1]+t[k]*(lambda-w))
    b <- exp(-lambda*t[j]+t[k-1]*(lambda-w))-exp(-lambda*t[j+1]+t[k-1]*(lambda-w))
    out <- out+(1-beta)^(j-k+1)*(a-b)
  }
  out <- (1-psi)*w/(lambda-w)*out 
  out <- out+(1-psi)*(exp(-w*t[j])-exp(-w*t[j+1])-w/(lambda-w)*(exp(-t[j+1]*w)-exp(-lambda*t[j+1]+(lambda-w)*t[j])))
  # correction 6/14
  out <- out*exp(w*t[1])
  return(out)
}

####################################################
# Interval-detected cancers: Likelihood contribution
# after last screen
#
# theta: model parameters
# t:     vector of times 
# l:     year of follow up [1, ..., L]
####################################################
Ifin.l <- function(theta, t, l){
  psi <- theta[1]
  lambda <- theta[2]
  w <- theta[3]
  beta <- theta[4]
  J <- length(t)-1 # index of last screen
  tJ <- t[J] # time of last screen
  L <- t[J+1]-t[J] # number of follow-up years after last screen
  out <- 0
  out <- exp(-lambda-w*(tJ+l-1))-exp(-l*lambda-w*tJ)  
  for(k in 2:J){
    out <- out+(1-beta)^(J-k+1)*(exp(-w*t[k]-lambda*(tJ+l-t[k]))-exp(-w*t[k-1]-lambda*(tJ+l-t[k-1])))
  }
  out <- out*w/(lambda-w)*(exp(lambda)-1)
  out <- out+exp(-w*(tJ+l-1))-exp(-w*(tJ+l))
  out <- out-w/(lambda-w)*(exp(-w*(tJ+l))-exp(-lambda-w*(tJ+l-1)))
  out <- (1-psi)*out
  # correction 6/14
  out <- out*exp(w*t[1])
  return(out)
}

####################################################
# Conditioning on T_P+T_C>t_0
#
# theta: model parameters
# t0:    time of first screen
####################################################
CF.fun <- function(theta, t0){
  psi <- theta[1]
  lambda <- theta[2]
  w <- theta[3]
  out <- psi+(1-psi)*(exp(-w*t0)+w/(lambda-w)*(exp(-t0*w)-exp(-t0*lambda)))
  return(out)
}

##################################################
# Full Likelihood with 4 parameters
# Use full likelihood to estimate 4 parameters
# psi:    proportion of non-progressive cancers
# lambda: exponential rate of progression to clinical
#         state for progressive cancers
# w:      incidence of preclinical disease (N->P/I)
# beta:   screening sensitivity
# 
# Hardcoded parameter inputs:
#   Time of onset of susceptibility to P/I 
#   Screening times
##################################################
EstPsiBMucstab4Full.fun <- function(x, y, t, z, clin.FU) {
  # x: vector of parameters (psi, lambda, w, beta)
  # y: rows are: y[1:3, ]=matrix(s[1], r[1], n[1],
  #                              s[2], r[2], n[2],
  #                              ..., ..., ...)
  #    where s is the number of screen detections and
  #          r is the number of interval cases
  #          n is the number of participants
  # z: if z[1] > 0: it is the number of parameters to be fixed
  #       z[2]: value of the parameter
  if (sum(z[[1]]) > 0){
    theta <- rep(-1, 4)
    theta[z[[1]]] <- z[[2]]
    theta[theta == -1] <- x
  } else {
    theta <- x
  }
  n.y <- nrow(y)
  
  ##################################################
  # Calculate probability of screen detection at
  # each exam
  ##################################################
  v <- t(0:(n.y-1))
  d <- apply(v, 2, function(x) D.j(theta, t, x))
  
  ##################################################
  # Calculate probability of clinical diagnosis in
  # each interval
  ##################################################
  q <- apply(v, 2, function(x) I.j(theta, t, x))
  
  ##################################################
  # Calculate and return full log likelihood
  ##################################################
  # old version with only one normalization term (approximation)
  #n.f <- rep(CF.fun(theta, t[2]-t[1]), n.y)
  #n.f <- rep(1, n.y)
  
  # NEW version with exact normalization terms
  n.f <- rep(CF.fun(theta, t[2]-t[1]), n.y)
  QQ <- cumsum(d+q)
  n.f[2:n.y] <- n.f[2:n.y]-QQ[1:(n.y-1)]
  fin <- 0
  
  # step 1: all but the last round
  for(jj in 1:(n.y-1)){
    fin <- fin-(y[jj, 1]*log(d[jj]/n.f[jj])+y[jj, 2]*log(q[jj]/n.f[jj])+(y[jj, 3]-y[jj, 1]-y[jj, 2])*log(1-d[jj]/n.f[jj]-q[jj]/n.f[jj]))
  }
  
  # step 2: the last round
  # The screen-detection contribution
  fin <- fin-y[n.y, 1]*log(d[n.y]/n.f[n.y])
  
  # The annual clinical incidence contributions
  p <- apply(t(1:length(clin.FU)), 2, function(x) Ifin.l(theta, t, x))
  fin <- fin-clin.FU %*% log(p/n.f[n.y])
  fin <- fin-(y[n.y, 3]-y[n.y, 1]-sum(clin.FU))*log(1-d[n.y]/n.f[n.y]-sum(p)/n.f[n.y])    
  return(fin)
}

##################################################
# Calculate profile likelihoods
##################################################
flikelihood <- function(x0,
                        xl,
                        xu,
                        t.vec,
                        trial.data,
                        last.screen,
                        z=c(0, 0),
                        likelihood=EstPsiBMucstab4Full.fun){
  opt <- nlminb(start=x0,
                obj=likelihood,
                lower=xl,
                upper=xu,
                y=trial.data,
                t=t.vec,
                z=z,
                clin.FU=last.screen)
  return(with(opt, list(objective=objective, params=par)))
}

plikelihood <- function(x0,
                        xl,
                        xu,
                        t.vec,
                        trial.data,
                        last.screen,
                        p.grid,
                        fopt=NA,
                        z=c(0, 0),
                        likelihood=EstPsiBMucstab4Full.fun,
                        problem=0,
                        noindolent=FALSE){
  nvalues <- nrow(p.grid)
  if(all(is.na(fopt)))
    fopt <- flikelihood(x0,
                        xl,
                        xu,
                        t.vec,
                        trial.data,
                        last.screen,
                        z=c(0, 0),
                        likelihood=likelihood)
  LL <- data.frame(psi=numeric(nvalues),
                   lambda=numeric(nvalues),
                   w=numeric(nvalues),
                   beta=numeric(nvalues))
  freenames <- allnames <- names(p.grid)
  if(noindolent){
    LL <- LL[-psi]
    freenames <- setdiff(freenames, 'psi')
  }
  for(fixed in freenames){
    for(j in 1:nvalues){
      if(noindolent)
        z <- list(c(1, match(fixed, allnames)), c(0, p.grid[j, fixed]))
      else
        z <- c(match(fixed, allnames), p.grid[j, fixed])
      popt <- nlminb(start=x0[setdiff(freenames, fixed)],
                     obj=likelihood,
                     lower=xl[setdiff(freenames, fixed)],
                     upper=xu[setdiff(freenames, fixed)],
                     y=trial.data,
                     t=t.vec,
                     z=z,
                     clin.FU=last.screen)
      problem <- problem+popt$convergence
      if(problem)
        warning('Convergence problem for ', fixed, '=', p.grid[j, fixed])
      LL[j, fixed] <- popt$objective-fopt$objective
    }
  }
  return(LL)
}

##################################################
# Control default plotting theme aesthetics
##################################################
gg_theme <- function(...){
  theme_set(theme_bw())
  theme_update(panel.grid.major=element_blank(),
               panel.grid.minor=element_blank(),
               panel.border=element_blank(),
               panel.spacing=unit(0.03, 'npc'),
               axis.text=element_text(colour='black', size=12),
               axis.title=element_text(size=12),
               axis.title.y=element_text(size=12, angle=90, vjust=0.5),
               axis.line=element_line(size=1, colour='black'),
               axis.ticks=element_line(size=1, colour='black'),
               strip.background=element_rect(fill=NA, colour=NA),
               strip.text.x=element_text(angle=0, size=12),
               plot.margin=unit(c(2, 1, 1, 2), 'lines'))
  theme_update(...)
}

##################################################
# Illustrate profile likelihoods
##################################################
pframe <- function(p.grid, p.like, parname, simulation=NA)
  data.frame(param=p.grid[, parname],
             NLL=pmax(p.like[, parname], 0),
             simulation=simulation)
```

```{r multiplot-function}
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

```{r figure2}
##################################################
# Simulation study parameters
# psi:    fraction of indolent cancers
# lambda: mean sojourn time for progressive cancers
# w:      hazard rate for onset of P/I
# beta:   screening sensitivity
##################################################
x.vec <- c(psi=0.2, lambda=1/2.5, w=0.0025, beta=0.8)

##################################################
# Initial values and limits for optimization algorithm
##################################################
x0 <- c(psi=0.5, lambda=1, w=1/100, beta=0.5)
xl <- c(psi=0, lambda=0, w=0, beta=0)
xu <- c(psi=1, lambda=5, w=5, beta=1)

##################################################
# t.vec:  vector of ages where w becomes >0, screens, and last follow-up
##################################################
t.vec <- c(20, 50:54, 60)

##################################################
# Generate the data
##################################################
set.seed(444)
source('synthetic_data_2017-06-26.r')

##################################################
# Calculate profile likelihood over parameter grid
##################################################
p.grid <- pgrid(x.vec)
p.like <- plikelihood(x0, xl, xu, t.vec, trial.data, last.screen, p.grid)

##################################################
# Save PDF of entire figure and EPS of each panel
# as requested by AJE technical review (turn off
# clipping to show letter designations on panels)
##################################################
addlegend <- function(gg){
  gt <- ggplot_gtable(ggplot_build(gg))
  key <- which(sapply(gt$grobs, function(x) x$name) == "guide-box")
  return(gt$grobs[[key]])
}

ajeformat <- function(panel_list,
                      number,
                      prefix=paste('AJE-01121-2017_Ryser', number, sep='_'),
                      index=0,
                      nrows=2,
                      ncols=2,
                      width=ncols*3,
                      height=nrows*3,
                      panel_ext='eps',
                      entire_ext='pdf',
                      panel_key=NULL){
    for(panel in panel_list){
      index <- index+1
      filename <- paste0(prefix, LETTERS[index])
      gt <- ggplot_gtable(ggplot_build(panel))
      gt$layout$clip[gt$layout$name == "panel"] <- "off"
      panel_list[[index]] <- gt
      ggsave(plot=gt,
             file=paste(filename, panel_ext, sep='.'),
             width=6,
             height=6)
    }
    entire <- arrangeGrob(grobs=panel_list,
                          nrow=nrows,
                          ncol=ncols)
    if(!is.null(panel_key)){
      key <- addlegend(panel_key)
      filename <- paste(prefix, 'key', sep='_')
      ggsave(plot=key,
             file=paste(filename, panel_ext, sep='.'),
             width=2,
             height=4)
      lwidth <- sum(key$width)
      entire <- arrangeGrob(entire,
                            key,
                            ncol=2,
                            widths=unit.c(unit(1, "npc")-lwidth,
                                          lwidth))
    }
    ggsave(plot=entire,
           file=paste(prefix, entire_ext, sep='.'),
           width=width,
           height=height)
}

##################################################
# Illustrate profile likelihoods
##################################################
ppanel <- function(x.vec,
                   p.grid,
                   p.like,
                   parname,
                   xmax=NA,
                   ymax=10,
                   xpad=1.05,
                   letter=NA){
  dset <- pframe(p.grid, p.like, parname)
  if(with(dset, which.min(NLL) > 1))
    lset <- with(subset(dset, param < param[which.min(NLL)]),
                 data.frame(param=approx(NLL, param, xout=ymax)$y,
                            NLL=ymax,
                            simulation=NA))
  else
    lset <- NULL
  if(with(dset, which.min(NLL) < length(param)))
    uset <- with(subset(dset, param > param[which.min(NLL)]),
                 data.frame(param=approx(NLL, param, xout=ymax)$y,
                            NLL=ymax,
                            simulation=NA))
  else
    uset <- NULL
  dset <- rbind(dset, lset, uset)
  dset <- subset(dset, NLL <= ymax)
  gg_theme()
  gg <- ggplot(data=dset)
  gg <- gg+geom_hline(yintercept=CI.line,
                      linetype='dotted',
                      colour='gray30',
                      size=0.75)
  gg <- gg+geom_vline(xintercept=x.vec[parname],
                      linetype='dashed',
                      colour='gray30',
                      size=0.75)
  gg <- gg+geom_line(aes(x=param, y=NLL), size=1)
  if(is.na(xmax)){
    xmax <- ifelse(parname == 'w', 0.01, 1)
    xstep <- ifelse(parname == 'w', 0.002, 0.2)
  } else {
    xstep <- xmax/5
  }
  if(parname == 'w')
    xbreaks <- c(0, 0.003, 0.006, 0.01)
  else
    xbreaks <- seq(0, xmax, by=xstep)
  gg <- gg+scale_x_continuous(name=parse(text=parname),
                              limits=c(0, xmax*xpad),
                              breaks=xbreaks,
                              expand=c(0, 0))
  gg <- gg+scale_y_continuous(name='Negative Log-Likelihood',
                              limits=c(-1, ymax),
                              breaks=seq(0, ymax, by=2),
                              expand=c(0, 0))
  if(!is.na(letter)){
    xlet <- ifelse(parname == 'w', -0.003, -0.3)
    xlet <- ifelse(parname == 'lambda' & xmax == 5, -1.5, xlet)
    gg <- gg+annotation_custom(grob=textGrob(label=paste0(letter, ')'),
                                             hjust=1),
                               xmin=xlet,
                               xmax=xlet,
                               ymin=ymax+1,
                               ymax=ymax+1)
  }
  return(gg)
}

if(aje_formatted){
  ppanel_a <- ppanel(x.vec, p.grid, p.like, 'psi', letter='A')
  ppanel_b <- ppanel(x.vec, p.grid, p.like, 'lambda', letter='B')
  ppanel_c <- ppanel(x.vec, p.grid, p.like, 'w', letter='C')
  ppanel_d <- ppanel(x.vec, p.grid, p.like, 'beta', letter='D')
  panel_list <- list(ppanel_a, ppanel_b, ppanel_c, ppanel_d)
  ajeformat(panel_list, 2)
}

grid.arrange(ppanel(x.vec, p.grid, p.like, 'psi'),
             ppanel(x.vec, p.grid, p.like, 'lambda'),
             ppanel(x.vec, p.grid, p.like, 'w'),
             ppanel(x.vec, p.grid, p.like, 'beta'),
             layout_matrix=matrix(c(1, 2, 3, 4),
                                  ncol=2,
                                  byrow=TRUE))
```

**FIGURE 2: Practical identifiability of mixture model.** A stop-screen trial with 50,000 subjects was simulated with annual screening at ages 50--54 years with follow-up to age 60 years. The outcomes were grouped by screening round to estimate the natural history parameters and screening sensitivity. The parameter values used to generate the synthetic data are indicated by vertical dashed lines, and the point estimates of the four parameters are close to the minima of the negative (profile) log-likelihoods. For each parameter, the intersection of the profile likelihood with the horizontal dotted line defines the 95% profile confidence interval.

\newpage

<!-- ```{r table1, echo=FALSE, results='asis'} -->
<!-- ################################################## -->
<!-- # Show example target and estimated parameters -->
<!-- ################################################## -->
<!-- load(file.path(loadpath, 'Bias_SE_Estimator', 'Bias_SE_stats_7_19_2017.RData')) -->
<!-- format_table1 <- function(dset){ -->
<!--   names(dset) <- sapply(names(dset), -->
<!--                         switch, -->
<!--                         'psi'='$\\psi$', -->
<!--                         'lambda'='$\\lambda$', -->
<!--                         'w'='$w$', -->
<!--                         'beta'='$\\beta$', -->
<!--                         'psi.se'='SE($\\hat{\\psi}$)', -->
<!--                         'lambda.se'='SE($\\hat{\\lambda}$)', -->
<!--                         'w.se'='SE($\\hat{w}$)', -->
<!--                         'beta.se'='SE($\\hat{\\beta}$)', -->
<!--                         'T2E'='T2E') -->
<!--   rownames(dset) <- c('Target', 'Estimate') -->
<!--   print(xtable(dset, digits=4, align=c('l', rep('c', 9))), -->
<!--         hline.after=0, -->
<!--         comment=FALSE, -->
<!--         sanitize.colnames.function=function(x) {x}) -->
<!-- } -->
<!-- format_table1(fff) -->
<!-- ``` -->

<!-- **TABLE 1: Bias and standard error of maximum likelihood estimators.** Example target and estimated parameters based on 1,000 Monte Carlo simulations. T2E stands for the rate of Type II errors, where the null hypothesis $\mathcal{H}_0: \psi=0$ was not rejected. -->

\newpage

```{r figure3, echo=FALSE}
##################################################
# Illustrate heatmaps of runs achieving API and
# runs rejecting H0: psi=0 with follow-up to
# specified ages
##################################################
apiplot <- function(dset,
                    par1='psi',
                    par2='lambda',
                    responses=c('IdM', 'LRM')){
  melted <- melt(dset, id.vars=c(par1, par2, 'followup'))
  melted <- rename(melted, c(variable='response', value='proportion'))
  melted <- subset(melted, response %in% responses)
  melted <- transform(melted,
                      followup=paste('Follow-up~to~age', followup, sep='~'),
                      response=sapply(as.character(response),
                                      switch,
                                      'IdM'='Runs~achieving~API',
                                      'LRM'='Runs~rejecting~psi==0'))
  gg_theme(axis.title=element_text(size=18),
           axis.title.y=element_text(size=18, angle=0, vjust=0.5),
           aspect.ratio=1,
           strip.text.y=element_text(angle=270, size=14))
  gg <- ggplot(data=melted, aes_string(x=par1, y=par2))
  gg <- gg+geom_raster(aes(fill=proportion), interpolate=FALSE)
  gg <- gg+facet_grid(response~followup, labeller=label_parsed)
  gg <- gg+scale_x_continuous(name=parse(text=par1),
                              breaks=seq(0, 0.75, by=0.25),
                              labels=percent_format(),
                              expand=c(0, 0))
  gg <- gg+scale_y_log10(name=parse(text=par2),
                         breaks=c(0.1, 0.5, 1.0, 2.0),
                         expand=c(0, 0))
  gg <- gg+scale_fill_gradient(name='',
                               labels=percent_format(),
                               low='black',
                               high='white',
                               limits=c(0, 1),
                               expand=c(0, 0),
                               guide=guide_colorbar(draw.ulim=FALSE,
                                                    draw.llim=FALSE,
                                                    label.hjust=1))
  print(gg)
}

apipanel <- function(dset,
                     Followup,
                     Response,
                     par1='psi',
                     par2='lambda',
                     ymax=2.9,
                     letter=NA){
  melted <- melt(dset, id.vars=c(par1, par2, 'followup'))
  melted <- rename(melted, c(variable='response', value='proportion'))
  melted <- subset(melted, followup == Followup & response == Response)
  gg_theme(axis.line=element_blank(),
           axis.title.y=element_text(size=12, angle=0, vjust=0.5),
           legend.position='none')
  gg <- ggplot(data=melted, aes_string(x=par1, y=par2))
  gg <- gg+geom_raster(aes(fill=proportion), interpolate=FALSE)
  gg <- gg+scale_x_continuous(name=parse(text=par1),
                              breaks=seq(0, 0.75, by=0.25),
                              expand=c(0, 0))
  gg <- gg+scale_y_log10(name=parse(text=par2),
                         breaks=c(0.1, 0.5, 1.0, 2.0),
                         expand=c(0, 0))
  gg <- gg+scale_fill_gradient(name='',
                               labels=percent_format(),
                               low='black',
                               high='white',
                               limits=c(0, 1),
                               expand=c(0, 0),
                               guide=guide_colorbar(draw.ulim=FALSE,
                                                    draw.llim=FALSE,
                                                    label.hjust=1))
  if(is.na(letter))
    gg <- gg+theme(legend.position='right')
  else {
    xlet <- ifelse(par1 == 'w', -0.003, -0.3)
    gg <- gg+annotation_custom(grob=textGrob(label=paste0(letter, ')'),
                                             hjust=1),
                               xmin=xlet,
                               xmax=xlet,
                               ymin=log10(ymax),
                               ymax=log10(ymax))
  }
  return(gg)
}

##################################################
# Read and merge saved results of runs achieving
# API and runs rejecting H0: psi=0 after 1 or 6
# years of clinical follow-up after last screen.
##################################################
load(file.path(loadpath, 'Systematic_IA_60', 'Exp_60_identifiability.RData'))
result_mat_60 <- transform(result_mat, IdM=IdM/max(IdM), LRM=LRM/max(LRM))

load(file.path(loadpath, 'Systematic_IA_55', 'Exp_55_identifiability.RData'))
result_mat_55 <- transform(result_mat, IdM=IdM/max(IdM), LRM=LRM/max(LRM))

dset <- rbind(transform(result_mat_55, followup=55),
              transform(result_mat_60, followup=60))

if(aje_formatted){
  apipanel_a <- apipanel(dset, Followup=55, Response='IdM', letter='A')
  apipanel_b <- apipanel(dset, Followup=60, Response='IdM', letter='B')
  apipanel_c <- apipanel(dset, Followup=55, Response='LRM', letter='C')
  apipanel_d <- apipanel(dset, Followup=60, Response='LRM', letter='D')
  apipanel_k <- apipanel(dset, Followup=60, Response='LRM')
  panel_list <- list(apipanel_a, apipanel_b, apipanel_c, apipanel_d)
  ajeformat(panel_list, 3, panel_key=apipanel_k)
}

apiplot(dset)
```

**FIGURE 3: Adequately Precise Identification (API) and type I/II errors.** Model performance over a range of values for the indolent fraction ($\psi$) and the progression rate of progressive cancers ($\lambda$) visualized as (top row) percentages of 100 simulations achieving joint API for all four model parameters and (bottom row) percentages of 100 simulations that reject the null hypothesis $\mathcal{H}_0: \psi=0$. Performance is visualized for 50,000 women screened annually at ages 50--54 years with follow-up to age 55 years (left column) and age 60 years (right column), assuming a constant risk of onset of preclinical cancer of $w=0.0025$ per year and sensitivity of screening to detect preclinical cancer of $\beta=80\%$.

\newpage

```{r figure4a, echo=FALSE, cache=TRUE}
##################################################
# Read saved results of simulations achieving API
##################################################
load(file.path(loadpath, 'Systematic_FU', 'Systematic_FU_psi_p2.RData'))
psi.p4 <- data.frame(psi=0.4, api=result_mat$IdM)

load(file.path(loadpath, 'Systematic_FU', 'Systematic_FU_psi_p4.RData'))
psi.p6 <- data.frame(psi=0.6, api=result_mat$IdM)

load(file.path(loadpath, 'Systematic_FU', 'Systematic_FU_psi_p6.RData'))
psi.p8 <- data.frame(psi=0.8, api=result_mat$IdM)

psi.dat <- rbind(psi.p4, psi.p6, psi.p8)

##################################################
# Calculate follow-up since final screen using
# time vector excluding last entry
##################################################
screen.vec <- c(20, 50:54)
fu.years <- FU.bound-screen.vec[length(screen.vec)]
psi.dat <- cbind(psi.dat, fu.years)

##################################################
# Illustrate simulations achieving API
##################################################
apanel <- function(dset, titulo, xmax=10, ymax=1, letter=NA){
  dset <- transform(dset, psi=factor(psi))
  gg_theme(legend.position='none')
  gg <- ggplot(data=dset)
  gg <- gg+geom_line(aes(x=fu.years,
                         y=api/100,
                         group=psi,
                         colour=psi),
                     size=1)
  gg <- gg+geom_point(aes(x=fu.years,
                          y=api/100,
                          group=psi,
                          colour=psi),
                      size=4)
  gg <- gg+scale_x_continuous(name='Years of Follow-up',
                              limits=c(0, xmax),
                              breaks=seq(0, xmax, by=2))
  gg <- gg+scale_y_continuous(name='% of Runs Achieving API',
                              limits=c(0, ymax),
                              breaks=seq(0, ymax, by=0.2))
  gg <- gg+scale_colour_grey()
  if(is.na(letter))
    gg <- gg+ggtitle(titulo)
  else
    gg <- gg+annotation_custom(grob=textGrob(label=paste0(letter, ')'),
                                             hjust=1),
                               xmin=-4,
                               xmax=-4,
                               ymin=ymax+0.1,
                               ymax=ymax+0.1)
  return(gg)
}

aaa <- psi.dat
#print(apanel(psi.dat))
```

```{r figure4b, echo=FALSE, cache=TRUE}
##################################################
# Read saved results of simulations achieving API
##################################################
load(file.path(loadpath, 'Systematic_FU', 'Systematic_FU_MST_4_psi_p2.RData'))
psi.p4 <- data.frame(psi=0.4, api=result_mat$IdM)

load(file.path(loadpath, 'Systematic_FU', 'Systematic_FU_MST_4_psi_p4.RData'))
psi.p6 <- data.frame(psi=0.6, api=result_mat$IdM)

load(file.path(loadpath, 'Systematic_FU', 'Systematic_FU_MST_4_psi_p6.RData'))
psi.p8 <- data.frame(psi=0.8, api=result_mat$IdM)

psi.dat <- rbind(psi.p4, psi.p6, psi.p8)

##################################################
# Calculate follow-up since final screen using
# time vector excluding last entry
##################################################
screen.vec <- c(20, 50:54)
fu.years <- FU.bound-screen.vec[length(screen.vec)]
psi.dat <- cbind(psi.dat, fu.years)

##################################################
# Juxtapose simulations with mean sojourn times of
# 6 months or 4 years using multiplot
##################################################
bbb <- psi.dat

if(aje_formatted){
  apanel_a <- apanel(aaa, letter='A')
  apanel_b <- apanel(bbb, letter='B')
  panel_list <- list(apanel_a, apanel_b)
  ajeformat(panel_list, 4, nrows=1)
}

multiplot(apanel(aaa, 'MST of 6 months'),
          apanel(bbb, 'MST of 4 years'),
          cols=2)
```

**FIGURE 4: API as a function of follow up.** Percentages of 100 simulations achieving joint API for all four model parameters in a stop-screen trial with 50,000 women screened annually at ages 50--54 years, by years of follow-up after the last screen. Mean sojourn time is (left panel) 6 months and (right panel) 4 years. Lines connect evaluations under $\psi$ set equal to (dark) 20%, (medium) 40%, and (light) 60%, assuming a constant rate of onset of preclinical cancer of $w=0.0025$ per year and sensitivity of screening to detect preclinical cancer of $\beta=80\%$.

\newpage

```{r simulations, cache=TRUE, echo=FALSE}
##################################################
# Fixed simulation study parameters
##################################################
x.vec <- c(psi=0.6, lambda=2, w=0.0025, beta=0.8)
x0 <- c(psi=0.5, lambda=1, w=1/100, beta=0.5)
xl <- c(psi=0, lambda=0, w=0, beta=0)
xu <- c(psi=1, lambda=5, w=5, beta=1)
sss <- 444

##################################################
# Simulation 1
##################################################
t.vec <- c(0, 50:54, 54)
set.seed(sss)
source('synthetic_data_2017-06-26.r')
p.grid <- pgrid(x.vec, scale.factor=10)
p.like <- plikelihood(x0, xl, xu, t.vec, trial.data, last.screen, p.grid)
p.psi.1 <- pframe(p.grid, p.like, 'psi', 1)
p.lambda.1 <- pframe(p.grid, p.like, 'lambda', 1)

##################################################
# Simulation 2
##################################################
t.vec <- c(0, 50:54, 56)
set.seed(sss)
source('synthetic_data_2017-06-26.r')
p.grid <- pgrid(x.vec, scale.factor=10)
p.like <- plikelihood(x0, xl, xu, t.vec, trial.data, last.screen, p.grid)
p.psi.2 <- pframe(p.grid, p.like, 'psi', 2)
p.lambda.2 <- pframe(p.grid, p.like, 'lambda', 2)

##################################################
# Simulation 3
##################################################
t.vec <- c(0, 50:54, 58)
set.seed(sss)
source('synthetic_data_2017-06-26.r')
p.grid <- pgrid(x.vec, scale.factor=10)
p.like <- plikelihood(x0, xl, xu, t.vec, trial.data, last.screen, p.grid)
p.psi.3 <- pframe(p.grid, p.like, 'psi', 3)
p.lambda.3 <- pframe(p.grid, p.like, 'lambda', 3)

##################################################
# Simulation 4
##################################################
t.vec <- c(0, 50:54, 60)
set.seed(sss)
source('synthetic_data_2017-06-26.r')
p.grid <- pgrid(x.vec, scale.factor=10)
p.like <- plikelihood(x0, xl, xu, t.vec, trial.data, last.screen, p.grid)
p.psi.4 <- pframe(p.grid, p.like, 'psi', 4)
p.lambda.4 <- pframe(p.grid, p.like, 'lambda', 4)
```

```{r figure5, cache=TRUE, echo=FALSE}
##################################################
# Merged results across simulations
##################################################
p.psi <- rbind(p.psi.1, p.psi.2, p.psi.3, p.psi.4)
p.lambda <- rbind(p.lambda.1, p.lambda.2, p.lambda.3, p.lambda.4)

##################################################
# Illustrate profile likelihoods
##################################################
spanel <- function(x.vec,
                   dset,
                   parname,
                   ymax=10,
                   xpad=1.05,
                   letter=NA){
  lset <- plyr::ddply(dset,
                      'simulation',
                      function(x)
                        with(subset(x, param < param[which.min(NLL)]),
                             data.frame(param=approx(NLL, param, xout=ymax)$y,
                                        NLL=ymax,
                                        simulation=unique(simulation))))
  if(parname == 'psi')
    uset <- plyr::ddply(dset,
                        'simulation',
                        function(x)
                          with(subset(x, param > param[which.min(NLL)]),
                               data.frame(param=approx(NLL, param, xout=ymax)$y,
                                          NLL=ymax,
                                          simulation=unique(simulation))))
  else
    uset <- NULL
  dset <- rbind(dset, lset, uset)
  dset <- subset(dset, NLL <= ymax)
  dset <- transform(dset, simulation=factor(simulation))
  gg_theme(legend.position='none')
  gg <- ggplot(data=dset)
  gg <- gg+geom_line(aes(x=param,
                         y=NLL,
                         group=simulation,
                         colour=simulation),
                     size=1)
  gg <- gg+geom_hline(yintercept=CI.line,
                      linetype='dotted',
                      colour='gray30',
                      size=0.75)
  gg <- gg+geom_vline(xintercept=x.vec[parname],
                      linetype='dashed',
                      colour='gray30',
                      size=0.75)
  xmax <- switch(parname, 'psi'=1, 'lambda'=20, 'w'=0.01, 'beta'=1)
  xstep <- switch(parname, 'psi'=0.2, 'lambda'=5, 'w'=0.002, 'beta'=0.2)
  xlet <- switch(parname, 'psi'=-0.3, 'lambda'=-6, 'w'=-0.004, 'beta'=-0.4)
  gg <- gg+scale_x_continuous(name=parse(text=parname),
                              limits=c(0, xmax*xpad),
                              breaks=seq(0, xmax, by=xstep),
                              expand=c(0, 0))
  gg <- gg+scale_y_continuous(name='Negative Log-Likelihood',
                              limits=c(-0.5, ymax),
                              breaks=seq(0, 100, by=2),
                              expand=c(0, 0))
  gg <- gg+scale_colour_grey(name='')
  if(!is.na(letter))
    gg <- gg+annotation_custom(grob=textGrob(label=paste0(letter, ')'),
                                             hjust=1),
                               xmin=xlet,
                               xmax=xlet,
                               ymin=ymax+1,
                               ymax=ymax+1)
  return(gg)
}

if(aje_formatted){
  spanel_a <- spanel(x.vec, p.psi, 'psi', letter='A')
  spanel_b <- spanel(x.vec, p.lambda, 'lambda', letter='B')
  panel_list <- list(spanel_a, spanel_b)
  ajeformat(panel_list, 5, nrows=1)
}

grid.arrange(spanel(x.vec, p.psi, 'psi'),
             spanel(x.vec, p.lambda, 'lambda'),
             layout_matrix=matrix(c(1, 2), ncol=2, byrow=TRUE))
```

**FIGURE 5: Identifiability as a function of follow up.** Profile likelihoods of $\psi$ and $\lambda$ for representative realizations of the $\psi=60\%$ scenario in Figure 4 (left panel). With 0 years follow up (black lines), $\lambda$ is practically non-identifiable. With 2 years follow up (dark grey lines), $\lambda$ is practially identifiable, but does not satisfy API. With 4 and 6 years of follow up (grey and light grey lines), $\lambda$ is clearly API. The remaining parameters $\beta$ and $w$ are API under all considered follow-up scenarios (results not shown). Simulation parameters as follows: 50,000 trial participants, $\lambda=2$, $w=0.0025$, and $\beta=80\%$.

\newpage

```{r figure6, cache=TRUE, echo=FALSE}
##################################################
# Simulation study parameters
##################################################
x.vec <- c(psi=0.2, lambda=1/2.5, w=0.0025, beta=0.8)

##################################################
# Read saved results of mis-specified model with
# no indolent cancers
##################################################
load(file.path(loadpath, 'Misspecification', 'Misspecification_beta_p8.RData'))
mis.dat <- transform(result_mat, psi=as.numeric(as.character(psi)))

##################################################
# Illustrate estimates under mis-specified model
##################################################
mpanel <- function(x.vec,
                   dset,
                   parname,
                   letter=NA){
  yspan <- diff(range(dset[[parname]]))
  ymax <- max(dset[[parname]])+0.15*yspan
  gg_theme(axis.title.y=element_text(angle=0))
  gg <- ggplot(data=dset)
  gg <- gg+geom_hline(yintercept=x.vec[parname],
                      linetype='dashed',
                      colour='gray30',
                      size=0.75)
  gg <- gg+geom_violin(aes_string(x='psi',
                                  y=parname,
                                  group='psi'))
  gg <- gg+scale_x_continuous(name=parse(text='psi'),
                              limits=c(-0.1, 1.1),
                              breaks=seq(0, 1, by=0.2))
  if(parname == 'w'){
    ybreaks <- seq(0.0023, 0.0035, by=0.0002)
    gg <- gg+scale_y_continuous(name=parse(text=parname),
                                limits=c(0.0022, 0.0036),
                                breaks=ybreaks)
  } else
    gg <- gg+scale_y_continuous(name=parse(text=parname))
  if(!is.na(letter)){
    xlet <- ifelse(parname == 'w', -0.8, -0.6)
    gg <- gg+annotation_custom(grob=textGrob(label=paste0(letter, ')'),
                                             hjust=1),
                               xmin=xlet,
                               xmax=xlet,
                               ymin=ymax,
                               ymax=ymax)
  }
  return(gg)
}

if(aje_formatted){
  mpanel_a <- mpanel(x.vec, mis.dat, 'w', letter='A')
  mpanel_b <- mpanel(x.vec, mis.dat, 'lambda', letter='B')
  mpanel_c <- mpanel(x.vec, mis.dat, 'beta', letter='C')
  panel_list <- list(mpanel_a, mpanel_b, mpanel_c)
  ajeformat(panel_list, 6, nrows=1, ncols=3)
}

grid.arrange(mpanel(x.vec, mis.dat, 'w'),
             mpanel(x.vec, mis.dat, 'lambda'),
             mpanel(x.vec, mis.dat, 'beta'),
             layout_matrix=matrix(c(1, 2, 3), ncol=3, byrow=TRUE))
```

**FIGURE 6: Model misspecification.** Violin plots of maximum likelihood estimates for parameters in a progressive model (i.e., one that assumes $\psi=0$) fit to data generated using a mixture model with selected values of $\psi\ge0$ assuming 50,000 women were screened annually at ages 50--54 with follow-up to age 60 years and the screening test has 80% sensitivity. Dashed horizontal lines indicate true parameter values. Results based on $n=200$ simulations per $\psi$-value.

\newpage

```{r figure7, results='asis'}
##################################################
# Analysis of CNBSS-2 for Ages 50-59
# Onset at age 45
##################################################
ind.FU <- 1  # clinical follow up

##################################################
# Read saved trial data
##################################################
source('trials_FU.r')
t.vec <- c(45, 55, 56, 57, 58, 59, 59+ind.FU)
cnbss.combo <- cnbss50
clin.FU <- FU.50

##################################################
# Initial values and limits for optimization algorithm
##################################################
x0 <- c(psi=0.2, lambda=0.05, w=1/1000, beta=0.6)
xl <- c(psi=0, lambda=0, w=0, beta=0)
xu <- c(psi=1, lambda=10, w=5, beta=1)

##################################################
# Profile likelihoods for mixture model
##################################################
f.like <- flikelihood(x0, xl, xu, t.vec, cnbss.combo, clin.FU)
p.grid <- pgrid(f.like$params, scale.factor=10)
p.like <- plikelihood(x0, xl, xu, t.vec, cnbss.combo, clin.FU, p.grid, f.like)

##################################################
# Illustrate mixture model profile likelihoods
##################################################
if(aje_formatted){
  ppanel_a <- ppanel(f.like$params, p.grid, p.like, 'psi', xmax=1, letter='A')
  ppanel_b <- ppanel(f.like$params, p.grid, p.like, 'lambda', xmax=5, letter='B')
  ppanel_c <- ppanel(f.like$params, p.grid, p.like, 'w', letter='C')
  ppanel_d <- ppanel(f.like$params, p.grid, p.like, 'beta', letter='D')
  panel_list <- list(ppanel_a, ppanel_b, ppanel_c, ppanel_d)
  ajeformat(panel_list, 7)
}

mixture <- arrangeGrob(ppanel(f.like$params, p.grid, p.like, 'psi', xmax=1),
                       ppanel(f.like$params, p.grid, p.like, 'lambda', xmax=5),
                       ppanel(f.like$params, p.grid, p.like, 'w'),
                       ppanel(f.like$params, p.grid, p.like, 'beta'),
                       layout_matrix=matrix(c(1, 2, 3, 4),
                                            ncol=2,
                                            byrow=TRUE))

##################################################
# Summarize point estimates and 95% profile CIs
##################################################
plot(mixture)
```

**Figure 7: Profile likelihood for CNBSS-2: mixture model.**  Relative negative log-likelihoods (NLL) based on fitting the mixture model to CNBSS-2 data (see Table S1). Vertical dashed lines correspond to maximum likelihood estimates. Intersection of relative NLL with horizontal dotted lines indicate the profile-based 95% confidence intervals. 

\newpage 

## SUPPLEMENTARY FIGURES AND TABLES

```{r cnbss2-data-table, results='asis', echo=FALSE}
warning('Supplemental tables and figures not reviewed after changes for AJE format')
# Like Table 1 in Shen et al. (2017) but including 5th screening round
source('trials_FU.R')
cnbprint <- data.frame(Round=c(1, 2, 3, 4, 5))
cnbprint <- cbind(cnbprint, cnbss50[, c(3, 1, 2)])
colnames(cnbprint) <- c('Screening round', 'No. of women', 'Screen-detected cases', 'Interval-detected cases')
print(xtable(cnbprint, align=rep('c', 5), digits=0),
      include.rownames=FALSE,
      hline.after=0,
      comment=FALSE,
      sanitize.colnames.function=function(x) {x})
```

**Table S1: CNBSS-2 data.** Grouped data from the Canadian Breast Cancer Screening Study-2 [Miller et al., CMAJ, 1992]. ``No. of women'' is the number of women who attended all screening rounds up to and including the current round.

\newpage

```{r sample-size-sensitivity, echo=FALSE}
##################################################
# Illustrate heatmaps of sensitivity of bias or SE
# to sample size
##################################################
sizeplot <- function(dset, par1, par2, response, zlimits){
  melted <- melt(dset, id.vars=c(par1, par2, 'followup'))
  melted <- transform(melted,
                      measure=sub('^([^_]*)_([^_]*)$', '\\1', variable),
                      variable=sub('^([^_]*)_([^_]*)$', '\\2', variable))
  melted <- transform(melted,
                      variable=factor(variable,
                                      levels=c('psi', 'lambda', 'w', 'beta')),
                      followup=paste('Follow-up~to~age', followup, sep='~'),
                      value=abs(value))
  melted <- subset(melted, measure == response, select=-measure)
  gg_theme(axis.title=element_text(size=18),
           axis.title.y=element_text(size=18, angle=0, vjust=0.5),
           panel.spacing=unit(0.01, 'npc'),
           aspect.ratio=1,
           strip.text.x=element_text(angle=0, size=12),
           strip.text.y=element_text(angle=0, size=14))
  gg <- ggplot(data=melted, aes_string(x=par1, y=par2))
  gg <- gg+geom_raster(aes(fill=value), interpolate=FALSE)
  gg <- gg+facet_grid(variable~followup, labeller=label_parsed)
  gg <- gg+scale_x_continuous(name=parse(text=par1),
                              breaks=seq(0, 0.75, by=0.25),
                              labels=percent_format(),
                              expand=c(0, 0))
  gg <- gg+scale_y_log10(name=parse(text=par2),
                         breaks=c(0.1, 0.5, 1.0, 2.0),
                         expand=c(0, 0))
  gg <- gg+scale_fill_gradient(name='',
                               low='white',
                               high='black',
                               limits=zlimits,
                               guide=guide_colorbar(draw.ulim=FALSE,
                                                    draw.llim=FALSE,
                                                    label.hjust=1))
  print(gg)
}

##################################################
# Read and merge saved results of bias and SEs
##################################################
load(file.path(loadpath, 'Systematic_IA_55', 'Exp_55_bias_se.RData'))
result_mat_55 <- result_mat

load(file.path(loadpath, 'Systematic_IA_60', 'Exp_60_bias_se.RData'))
result_mat_60 <- result_mat

dset <- rbind(transform(result_mat_55, followup=55),
              transform(result_mat_60, followup=60))
```

```{r sample-size-bias, fig.width=8, echo=FALSE}
##################################################
# Illustrate sensitivity of bias to follow-up
##################################################
sizeplot(dset, par1='psi', par2='lambda', response='bias', zlimits=c(0, 1))
```

**FIGURE S1: Sensitivity of bias to follow up.** Absolute bias for all four model parameters assuming 50,000 women were screened annually at ages 50--54 years with follow-up to age 55 years (left column) and age 60 years (right column). Screening test sensitivity was set to $\beta=80\%$.

\newpage

```{r sample-size-se, fig.width=8, echo=FALSE}
##################################################
# Illustrate sensitivity of SEs to follow-up
##################################################
sizeplot(dset, par1='psi', par2='lambda', response='SE', zlimits=c(0, 2))
```

**FIGURE S2: Sensitivity of the standard error to follow up.** Standard errors for all four model parameters assuming 50,000 women were screened annually at ages 50--54 years with follow-up to age 55 years (left column) and age 60 years (right column). Screening test sensitivity was set to $\beta=80\%$.

\newpage

```{r misspecification}
##################################################
# Simulation stßudy parameters
##################################################
x.vec <- c(psi=0.2, lambda=1/2.5, w=0.0025, beta=0.4)

##################################################
# Read saved results of mis-specified model with
# no indolent cancers
##################################################
load(file.path(loadpath, 'Misspecification', 'Misspecification_beta_p4.RData'))
mis.dat <- transform(result_mat, psi=as.numeric(as.character(psi)))

##################################################
# Illustrate estimates under mis-specified model
##################################################
grid.arrange(mpanel(x.vec, mis.dat, 'w'),
             mpanel(x.vec, mis.dat, 'lambda'),
             mpanel(x.vec, mis.dat, 'beta'),
             layout_matrix=matrix(c(1, 2, 3), ncol=3, byrow=TRUE))
```

**FIGURE S3: Model misspecification.** Violin plots of maximum likelihood estimates for parameters in a progressive model (i.e., one that assumes $\psi=0$) fit to data generated using a mixture model with selected values of $\psi\ge0$ assuming 50,000 women were screened annually at ages 50--54 with follow-up to age 60 years and the screening test has 40% sensitivity. Results based on $n=200$ simulations per $\psi$-value.

\newpage

```{r}
#######################################################
# Prepare for the CI calculation for CNBSS-2
#######################################################
plikelihood_fix <- function(x0,
                            xl,
                            xu,
                            t.vec,
                            trial.data,
                            last.screen,
                            p.grid,
                            fopt=NA,
                            z=c(0, 0),
                            likelihood=EstPsiBMucstab4Full.fun,
                            problem=0,
                            noindolent=FALSE){
  nvalues <- nrow(p.grid)
  psi_fix <- z[2]
  if(all(is.na(fopt)))
    fopt <- flikelihood(x0,
                        xl,
                        xu,
                        t.vec,
                        trial.data,
                        last.screen,
                        z=c(1, psi_fix),
                        likelihood=likelihood)
  LL <- data.frame(psi=numeric(nvalues),
                   lambda=numeric(nvalues),
                   w=numeric(nvalues),
                   beta=numeric(nvalues))
  freenames <- allnames <- names(p.grid)
  if(noindolent){
    LL <- LL[-psi]
    freenames <- setdiff(freenames, 'psi')
  }
  for(fixed in freenames){
    for(j in 1:nvalues){
      if(noindolent)
        z <- list(c(1, match(fixed, allnames)), c(psi_fix, p.grid[j, fixed]))
      else
        z <- c(match(fixed, allnames), p.grid[j, fixed])
      popt <- nlminb(start=x0[setdiff(freenames, fixed)],
                     obj=likelihood,
                     lower=xl[setdiff(freenames, fixed)],
                     upper=xu[setdiff(freenames, fixed)],
                     y=trial.data,
                     t=t.vec,
                     z=z,
                     clin.FU=last.screen)
      problem <- problem+popt$convergence
      if(problem)
        warning('Convergence problem for ', fixed, '=', p.grid[j, fixed])
      LL[j, fixed] <- popt$objective-fopt$objective
    }
  }
  return(LL)
}

progressive <- arrangeGrob(ppanel(f.like$params, p.grid, p.like, 'lambda', xmax=2),
                           ppanel(f.like$params, p.grid, p.like, 'w', xmax=0.005),
                           ppanel(f.like$params, p.grid, p.like, 'beta'),
                           layout_matrix=matrix(c(1, 2, 3),
                                                ncol=3,
                                                byrow=TRUE))

ptable <- function(f.like, p.grid, p.like){
  ests <- f.like$params
  ptab <- NULL
  for(parname in names(ests)){
    limits <- range(p.grid[p.like[, parname] < CI.line, parname])
    lower <- ifelse(limits[1] == p.grid[1, parname], NA, limits[1])
    upper <- ifelse(limits[2] == p.grid[nrow(p.grid), parname], NA, limits[2])
    ptab <- rbind(ptab, c(lower, upper))
  }
  colnames(ptab) <- c('95% lower', '95% upper')
  parnames <- sapply(names(ests),
                     switch,
                     'psi'='$\\psi$',
                     'lambda'='$\\lambda$',
                     'w'='$w$',
                     'beta'='$\\beta$')
  ptab <- data.frame(Estimate=ests,
                     ptab,
                     row.names=parnames,
                     check.names=FALSE)
  print(xtable(ptab, digits=4, align=c('l', rep('c', 3))),
        hline.after=0,
        comment=FALSE,
        sanitize.rownames.function=function(x) {x})
}
```

```{r cnbss-progressive}
##################################################
# Illustrate progressive model profile likelihoods
##################################################
grid.draw(progressive)
#plot(progressive)
```

**Figure S3: Fitting progressive model to CNBSS-II data.** Profile likelihoods for the three model parameters are shown assuming 50,000 women were screened annually at ages 50--54 with follow-up to age 55 years (Table S1).

\newpage

```{r cnbss-mixture}
##################################################
# Illustrate progressive model profile likelihoods
##################################################
grid.draw(mixture)
#plot(mixture)
```

**Figure S4: Fitting mixture model to CNBSS-II data.** Profile likelihoods for the four mixture model parameters are shown assuming 50,000 women were screened annually at ages 50--54 with follow-up to age 55 years (Table S1).

\newpage

```{r cnbss2-table1, results='asis', echo=FALSE, comment=FALSE}
##################################################
# Fix psi at different values and find the MLE and GoF
##################################################
psi_fix <- c(0, 0.05, 0.1, 0.2, 0.4)
l.p <- length(psi_fix)
table_cnbss.1 <- data.frame(psi=psi_fix,
                            lambda=numeric(l.p),
                            lambda.CI.lr=numeric(l.p),
                            lambda.CI.up=numeric(l.p),
                            w=numeric(l.p),
                            w.CI.lr=numeric(l.p),
                            w.CI.up=numeric(l.p),
                            beta=numeric(l.p),
                            beta.CI.lr=numeric(l.p),
                            beta.CI.up=numeric(l.p),
                            statistic=numeric(l.p),
                            p_value=numeric(l.p))
cnbss50 <- matrix(c(142, 15, 19711,
                     66, 10, 17669,
                     43,  9, 17347,
                     54,  9, 17193,
                     28,  5, 9876),
                  byrow=TRUE,
                  ncol=3)
t.vec <- c(45, 55, 56, 57, 58, 59, 60)
n.y <- nrow(cnbss50)

##################################################
# MLE
##################################################
for(k in 1:nrow(table_cnbss.1)){
  #########
  # MLE
  #########
  f.like <- flikelihood(x0[-psi],
                        xl[-psi],
                        xu[-psi],
                        t.vec,
                        cnbss50,
                        clin.FU,
                        z=c(1, table_cnbss.1$psi[k]))
  table_cnbss.1$lambda[k] <- f.like$params[1]
  table_cnbss.1$w[k] <- f.like$params[2]
  table_cnbss.1$beta[k] <- f.like$params[3]
  
  #########
  # CI
  #########
  psi_fix=table_cnbss.1$psi[k]
  p.grid <- transform(pgrid(c(psi=psi_fix, f.like$params), scale.factor=5), psi=psi_fix)
  p.like <- plikelihood_fix(x0, xl, xu, t.vec, cnbss50, clin.FU, p.grid, f.like, z=c(1, psi_fix), noindolent=TRUE)
  
  ests <- f.like$params
  ptab <- NULL
  for(parname in names(ests)){
    limits <- range(p.grid[p.like[, parname] < CI.line, parname])
    lower <- ifelse(limits[1] == p.grid[1, parname], NA, limits[1])
    upper <- ifelse(limits[2] == p.grid[nrow(p.grid), parname], NA, limits[2])
    ptab <- rbind(ptab, c(lower, upper))
  }

  table_cnbss.1$lambda.CI.lr[k] <- ptab[1, 1]
  table_cnbss.1$lambda.CI.up[k] <- ptab[1, 2]
 
  table_cnbss.1$w.CI.lr[k] <- ptab[2, 1]
  table_cnbss.1$w.CI.up[k] <- ptab[2, 2]
 
  table_cnbss.1$beta.CI.lr[k] <- ptab[3, 1]
  table_cnbss.1$beta.CI.up[k] <- ptab[3, 2]
 
  #########
  # GoF
  #########

  sc_ex <- rep(0, n.y)  
  cl_ex <- rep(0, n.y)
 
  f.like <- flikelihood(x0[-psi], xl[-psi], xu[-psi], t.vec, cnbss50, clin.FU, z=c(1, table_cnbss.1$psi[k]))
 
  # Compute the likelihoods
  v <- t(0:(n.y-1))
  theta <- c(table_cnbss.1$psi[k], f.like$params)
  d <- apply(v, 2, function(x) D.j(theta, t.vec, x))
  q <- apply(v, 2, function(x) I.j(theta, t.vec, x))
 
  n.f <- rep(CF.fun(theta, t.vec[2]-t.vec[1]), n.y)
  QQ <- cumsum(d+q)
  n.f[2:n.y] <- n.f[2:n.y]-QQ[1:(n.y-1)]
 
  sc_ex <- d/n.f*cnbss50[, 3]
  cl_ex <- q/n.f*cnbss50[, 3]

  # Xi square statistic
  X <- sum((sc_ex-cnbss50[, 1])^2/sc_ex)+sum((cl_ex-cnbss50[, 2])^2/cl_ex)
  rem_ex <- cnbss50[, 3]-sc_ex-cl_ex
  rem_ob <- cnbss50[, 3]-cnbss50[, 1]-cnbss50[, 2]
  X <- X+sum((rem_ex-rem_ob)^2/rem_ex)
  table_cnbss.1$statistic[k] <- X
  table_cnbss.1$p_value[k] <- 1-pchisq(X, df=2*n.y)
}

##################################################
# Output
##################################################
table.s2 <- with(table_cnbss.1, data.frame('$\\psi$'=sprintf('%4.2f', psi),
                                           '$\\hat{\\lambda}$'=sprintf('%4.2f', lambda),
                                           '95\\% CI'=paste(sprintf('%4.2f', lambda.CI.lr),
                                                            sprintf('%4.2f', lambda.CI.up),
                                                            sep='-'),
                                           '$\\hat{w}$'=sprintf('%6.4f', w),
                                           '95\\% CI'=paste(sprintf('%6.4f', w.CI.lr),
                                                            sprintf('%6.4f', w.CI.up),
                                                            sep='-'),
                                           '$\\hat{\\beta}$'=sprintf('%4.2f', beta),
                                           '95\\% CI'=paste(sprintf('%4.2f', beta.CI.lr),
                                                            sprintf('%4.2f', beta.CI.up),
                                                            sep='-'),
                                           '$\\chi^2$'=sprintf('%4.2f', statistic),
                                           'P-value'=sprintf('%6.4f', p_value),
                                           row.names=NULL,
                                           check.names=FALSE))
print(xtable(table.s2, align=rep('c', 10)),
      include.rownames=FALSE,
      hline.after=0,
      comment=FALSE,
      sanitize.colnames.function=function(x) {x})
```

**Table S2: CNBSS-2: parameter estimation and goodness of fit for constrained mixture model.** The mixture model with fixed fraction of indolent cancers $\psi$ is fit to the CNBSS-2 data (see Table S1). Onset of preclinical disease is assumed to be negligible before age $\Delta_0=45$ years.

\newpage 

```{r cnbss2-table2, results='asis', echo=FALSE}
##################################################
# Vary the length of the time interval of positive onset away from 45 years
##################################################
t_fix <- c(20, 15, 10, 5)
l.p <- length(t_fix)
n.y <- nrow(cnbss50)

table_cnbss.1 <- data.frame(age_onset=numeric(l.p),
                            psi=numeric(l.p),
                            psi.CI.lr=numeric(l.p),
                            psi.CI.up=numeric(l.p),
                            lambda=numeric(l.p),
                            lambda.CI.lr=numeric(l.p),
                            lambda.CI.up=numeric(l.p),
                            w=numeric(l.p),
                            w.CI.lr=numeric(l.p),
                            w.CI.up=numeric(l.p),
                            beta=numeric(l.p),
                            beta.CI.lr=numeric(l.p),
                            beta.CI.up=numeric(l.p),
                            statistic=numeric(l.p),
                            p_value=numeric(l.p))
cnbss50 <- matrix(c(142, 15, 19711,
                     66, 10, 17669,
                     43,  9, 17347,
                     54,  9, 17193,
                     28,  5, 9876),
                  byrow=TRUE,
                  ncol=3)

for(k in 1:nrow(table_cnbss.1)){
  t.vec <- c(55-t_fix[k], 55, 56, 57, 58, 59, 60)
  table_cnbss.1$age_onset[k] <- t.vec[1]
  
  #########
  # MLE
  #########
  f.like <- flikelihood(x0, xl, xu, t.vec, cnbss50, clin.FU, z=c(0, 0))
  table_cnbss.1$psi[k] <- f.like$params[1]
  table_cnbss.1$lambda[k] <- f.like$params[2]
  table_cnbss.1$w[k] <- f.like$params[3]
  table_cnbss.1$beta[k] <- f.like$params[4]
  
  #########
  # CI
  ######### 
  p.grid <- pgrid( f.like$params, scale.factor=5)
  p.like <- plikelihood_fix(x0, xl, xu, t.vec, cnbss50, clin.FU, p.grid, f.like, z=c(0, 0), noindolent=FALSE)
 
  ests <- f.like$params
  ptab <- NULL
  for(parname in names(ests)){
    limits <- range(p.grid[p.like[, parname] < CI.line, parname])
    lower <- ifelse(limits[1] == p.grid[1, parname], NA, limits[1])
    upper <- ifelse(limits[2] == p.grid[nrow(p.grid), parname], NA, limits[2])
    ptab <- rbind(ptab, c(lower, upper))
  }
 
  table_cnbss.1$psi.CI.lr[k] <- ptab[1, 1]
  table_cnbss.1$psi.CI.up[k] <- ptab[1, 2]
 
  table_cnbss.1$lambda.CI.lr[k] <- ptab[2, 1]
  table_cnbss.1$lambda.CI.up[k] <- ptab[2, 2]
 
  table_cnbss.1$w.CI.lr[k] <- ptab[3, 1]
  table_cnbss.1$w.CI.up[k] <- ptab[3, 2]
 
  table_cnbss.1$beta.CI.lr[k] <- ptab[4, 1]
  table_cnbss.1$beta.CI.up[k] <- ptab[4, 2]
 
  ########
  # GoF
  ########

  sc_ex <- rep(0, n.y)  
  cl_ex <- rep(0, n.y)
 
  f.like <- flikelihood(x0, xl, xu, t.vec, cnbss50, clin.FU, z=c(0, 0))
 
  # Compute the likelihoods
  v <- t(0:(n.y-1))
  theta <- f.like$params
  d <- apply(v, 2, function(x) D.j(theta, t.vec, x))
  q <- apply(v, 2, function(x) I.j(theta, t.vec, x))
 
  n.f <- rep(CF.fun(theta, t.vec[2]-t.vec[1]), n.y)
  QQ <- cumsum(d+q)
  n.f[2:n.y] <- n.f[2:n.y]-QQ[1:(n.y-1)]
 
  sc_ex <- d/n.f*cnbss50[, 3]
  cl_ex <- q/n.f*cnbss50[, 3]

  # Xi square statistic
  X <- sum((sc_ex-cnbss50[, 1])^2/sc_ex)+sum((cl_ex-cnbss50[, 2])^2/cl_ex)
  rem_ex <- cnbss50[, 3]-sc_ex-cl_ex
  rem_ob <- cnbss50[, 3]-cnbss50[, 1]-cnbss50[, 2]
  X <- X+sum((rem_ex-rem_ob)^2/rem_ex)
  table_cnbss.1$statistic[k] <- X
  table_cnbss.1$p_value[k] <- 1-pchisq(X, df=2*n.y)
}

table.s3 <- with(table_cnbss.1, data.frame('$\\Delta_0$'=sprintf('%d', age_onset),
                                           '$\\hat{\\psi}$'=sprintf('%4.2f', psi),
                                           '95\\% CI'=paste(sprintf('%4.2f', psi.CI.lr),
                                                            sprintf('%4.2f', psi.CI.up),
                                                            sep='-'),
                                           '$\\hat{\\lambda}$'=sprintf('%4.2f', lambda),
                                           '95\\% CI'=paste(sprintf('%4.2f', lambda.CI.lr),
                                                            sprintf('%4.2f', lambda.CI.up),
                                                            sep='-'),
                                           '$\\hat{w}$'=sprintf('%6.4f', w),
                                           '95\\% CI'=paste(sprintf('%6.4f', w.CI.lr),
                                                            sprintf('%6.4f', w.CI.up),
                                                            sep='-'),
                                           '$\\hat{\\beta}$'=sprintf('%4.2f', beta),
                                           '95\\% CI'=paste(sprintf('%4.2f', beta.CI.lr),
                                                            sprintf('%4.2f', beta.CI.up),
                                                            sep='-'),
                                           '$\\chi^2$'=sprintf('%4.2f', statistic),
                                           'P-value'=sprintf('%6.4f', p_value),
                                           row.names=NULL,
                                           check.names=FALSE))
print(xtable(table.s3, align=rep('c', 12)),
      include.rownames=FALSE,
      hline.after=0,
      comment=FALSE,
      sanitize.colnames.function=function(x) {x})
```

**Table S3: CNBSS-2: parameter estimation and goodness of fit for varying onset ages.** The mixture model is fit to the CNBSS-2 data (see Table S1) for varying ages of first possible onset of preclinical disease.

